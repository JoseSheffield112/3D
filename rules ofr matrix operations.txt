It is advised to first do scaling operations, then rotations and lastly translations when combining matrices otherwise they may (negatively) affect each other


OpenGL expects all the vertices, that we want to become visible, to be in normalized device coordinates after each vertex shader run. That is, the x, y and z coordinates of each vertex should be between -1.0 and 1.0

Important: remember that the matrices precede the vertices they are transforming. Thus they are in the order projection, view, model, so that the model matrix is the first applied to a vertex

 The method Mat4.toFloatArrayForGLSL() is used to do this. It converts the row-column ordered matrix into a column-row ordered matrix stored in an array of floats which is what is required in the data type used in the vertex shader. 

we can try to simulate one [camera] by moving all objects in the scene in the reverse direction, giving the illusion that we are moving

